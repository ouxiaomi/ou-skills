#!/usr/bin/env python3
"""
æŠ€èƒ½Hashæ£€æŸ¥å·¥å…·
ç”¨äºæ£€æµ‹é‡å¤çš„æŠ€èƒ½
"""

import os
import json
import hashlib
from pathlib import Path
from collections import defaultdict
from datetime import datetime

def compute_file_hash(filepath):
    """è®¡ç®—æ–‡ä»¶çš„SHA-256 hash"""
    sha256_hash = hashlib.sha256()
    with open(filepath, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            sha256_hash.update(chunk)
    return sha256_hash.hexdigest()

def scan_skills(repo_root):
    """æ‰«ææ‰€æœ‰æŠ€èƒ½"""
    skills = {}
    categories_path = Path(repo_root) / "categories"

    if not categories_path.exists():
        print(f"âŒ åˆ†ç±»ç›®å½•ä¸å­˜åœ¨: {categories_path}")
        return skills

    for skill_md in categories_path.rglob("SKILL.md"):
        skill_path = str(skill_md.relative_to(repo_root))
        skill_dir = str(skill_md.parent.relative_to(repo_root))

        skill_hash = compute_file_hash(skill_md)

        skills[skill_path] = {
            "path": skill_path,
            "dir": skill_dir,
            "hash": skill_hash,
            "size": skill_md.stat().st_size,
            "modified": datetime.fromtimestamp(skill_md.stat().st_mtime).isoformat()
        }

    return skills

def check_duplicates(skills):
    """æ£€æŸ¥é‡å¤æŠ€èƒ½"""
    hash_map = defaultdict(list)

    for path, info in skills.items():
        hash_map[info["hash"]].append(info)

    # æ‰¾å‡ºæœ‰é‡å¤çš„hash
    duplicates = {h: v for h, v in hash_map.items() if len(v) > 1}
    return duplicates

def save_hash_index(repo_root, skills):
    """ä¿å­˜hashç´¢å¼•"""
    hash_file = Path(repo_root) / ".skills-hash.json"

    index = {
        "version": "1.0",
        "lastUpdated": datetime.now().isoformat(),
        "totalSkills": len(skills),
        "skills": {path: {
            "hash": info["hash"],
            "size": info["size"],
            "modified": info["modified"]
        } for path, info in skills.items()}
    }

    with open(hash_file, "w", encoding="utf-8") as f:
        json.dump(index, f, indent=2, ensure_ascii=False)

    return hash_file

def main():
    import sys
    repo_root = Path(__file__).parent.parent

    print("ğŸ” æ‰«ææŠ€èƒ½å¹¶è®¡ç®—hash...\n")

    skills = scan_skills(repo_root)

    if not skills:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æŠ€èƒ½")
        return

    print(f"âœ… æ‰¾åˆ° {len(skills)} ä¸ªæŠ€èƒ½:\n")

    for path, info in sorted(skills.items()):
        print(f"  ğŸ“„ {path}")
        print(f"     Hash: {info['hash'][:16]}...")
        print(f"     å¤§å°: {info['size']} bytes\n")

    # æ£€æŸ¥é‡å¤
    duplicates = check_duplicates(skills)

    if duplicates:
        print("âš ï¸  å‘ç°é‡å¤æŠ€èƒ½!\n")
        for h, skill_list in duplicates.items():
            print(f"  Hash: {h[:16]}... ({len(skill_list)} ä¸ªé‡å¤é¡¹)")
            for skill in skill_list:
                print(f"    - {skill['path']}")
        print()
    else:
        print("âœ… æ²¡æœ‰å‘ç°é‡å¤æŠ€èƒ½\n")

    # ä¿å­˜ç´¢å¼•
    hash_file = save_hash_index(repo_root, skills)
    print(f"ğŸ’¾ Hashç´¢å¼•å·²ä¿å­˜: {hash_file}")

    # è¿”å›çŠ¶æ€ç ï¼ˆæœ‰é‡å¤è¿”å›1ï¼‰
    sys.exit(1 if duplicates else 0)

if __name__ == "__main__":
    main()
